{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " <script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%qtconsole\n",
    "\n",
    "import os\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import pandas\n",
    "from scipy import linalg\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.colors import from_levels_and_colors\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "figdir = 'Figs/'\n",
    "\n",
    "proxy_pandas_metafile = 'NCDC_v0.1.0all_Metadata.df.pckl'\n",
    "proxy_pandas_datafile = 'NCDC_v0.1.0all_Proxies.df.pckl'\n",
    "\n",
    "proxy_meta = pandas.read_pickle(proxy_pandas_metafile)\n",
    "proxy_data = pandas.read_pickle(proxy_pandas_datafile)\n",
    "\n",
    "# Reformat the proxy_meta to get rid of special characters\n",
    "proxy_meta.columns = [x.strip().replace(' ','_') for x in proxy_meta.columns]\n",
    "proxy_meta.columns = [x.strip().replace('(','') for x in proxy_meta.columns]\n",
    "proxy_meta.columns = [x.strip().replace(')','') for x in proxy_meta.columns]\n",
    "proxy_meta.columns = [x.strip().replace('.','') for x in proxy_meta.columns]\n",
    "\n",
    "# Change the metadata file so that indices are NCDC IDs (better matchup with data file)\n",
    "proxy_meta.index = proxy_meta['NCDC_ID']\n",
    "\n",
    "proxy_meta['Archive_type'] = proxy_meta['Archive_type'].str.replace(' ','_')\n",
    "\n",
    "# sort the metadata to have the same order as the data file\n",
    "proxy_meta = proxy_meta.loc[proxy_data.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeLIM(D,tau):\n",
    "    ''' Constructs a LIM using the equation of Penland (1996) etc. by computing two covariance matrices at lag 0 and lag tau.\n",
    "    D is a 2d matrix whos rows are indexed in time and whose columns correspond to different records.\n",
    "    Tau is a unit of time and should be specified in terms of the units indexing D in time (e.g., if D is yearly, a lag of two years is specified by tau = 2)'''\n",
    "    l,m = D.shape\n",
    "    Dt  = D.transpose()\n",
    "    c0 = np.cov(Dt)\n",
    "    #ctfull = np.cov(Dt[:,tau:],Dt[:,:-tau])\n",
    "    ctfull = np.cov(Dt[:,:-tau],Dt[:,tau:])\n",
    "    # relelvant portion is one of the off-diagonal covariance submatrices\n",
    "    ct = ctfull[m:,:-m]\n",
    "\n",
    "#    L = 1/tau*linalg.logm(ct*linalg.inv(c0))\n",
    "    G = np.dot(ct,linalg.inv(c0))\n",
    "    return G\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-0a1f21a34173>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-0a1f21a34173>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    -\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getSkill(data_types,proxy_data,proxy_meta,tau,calInt,valInt):\n",
    "    ''' Constructs a LIM using the equation of Penland (1996) etc. by computing two covariance matrices at lag 0 and lag tau.\n",
    "    D is a 2d matrix whos rows are indexed in time and whose columns correspond to different records.\n",
    "    Tau is a unit of time and should be specified in terms of the units indexing D in time (e.g., if D is yearly, a lag of two years is specified by tau = 2)\n",
    "    calInt and valInt are 2-element arrays specifying beginning and end years of calibration and validation intervals'''\n",
    "\n",
    "    #    tau = 5\n",
    "    #    calInt = [1800,1900]\n",
    "    #    valInt = [1900,1950]\n",
    "    #    data_types = {'c', 'i', 'm', 'l', 't'}\n",
    "\n",
    "    ###########\n",
    "    ## Setup ##\n",
    "    ###########\n",
    "\n",
    "    import os\n",
    "    import cPickle\n",
    "    import numpy as np\n",
    "    import pandas\n",
    "    from scipy import linalg\n",
    "\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.colors as colors\n",
    "    from matplotlib.figure import Figure\n",
    "    from matplotlib.colors import from_levels_and_colors\n",
    "    from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "    # Reformat the proxy_meta to get rid of special characters\n",
    "    proxy_meta.columns = [x.strip().replace(' ','_') for x in proxy_meta.columns]\n",
    "    proxy_meta.columns = [x.strip().replace('(','') for x in proxy_meta.columns]\n",
    "    proxy_meta.columns = [x.strip().replace(')','') for x in proxy_meta.columns]\n",
    "    proxy_meta.columns = [x.strip().replace('.','') for x in proxy_meta.columns]\n",
    "\n",
    "    # Change the metadata file so that indices are NCDC IDs (better matchup with data file)\n",
    "    proxy_meta.index = proxy_meta['NCDC_ID']\n",
    "\n",
    "    proxy_meta['Archive_type'] = proxy_meta['Archive_type'].str.replace(' ','_')\n",
    "\n",
    "    # sort the metadata to have the same order as the data file\n",
    "    proxy_meta = proxy_meta.loc[proxy_data.columns]\n",
    "\n",
    "    #####################################\n",
    "    ## Select archive types to be used ##\n",
    "    #####################################\n",
    "    groups = proxy_meta.groupby('Archive_type')\n",
    "\n",
    "    # Groups can be any of the following, coded by letters as specified in this dict:\n",
    "    data_dict = {'c': 'Corals_and_Sclerosponges', \n",
    "                 'i': 'Ice_Cores', \n",
    "                 'l': 'Lake_Cores',\n",
    "                 'm': 'Marine_Cores',\n",
    "                 's': 'Speleothems',\n",
    "                 't': 'Tree_Rings'}\n",
    "\n",
    "    tr = pandas.DataFrame()\n",
    "    for x in data_types:\n",
    "        test = groups.get_group(data_dict[x])\n",
    "        tr = pandas.concat([tr,test])\n",
    "        pmr = proxy_meta.loc[tr.index]\n",
    "        pdr = proxy_data[tr.index]\n",
    "\n",
    "    # Cut the data down to a relevant interval to speed binning\n",
    "    pdr = pdr[0:2013]\n",
    "\n",
    "########################################################\n",
    "## Bin data and subselect time frames for cal and val ## \n",
    "########################################################\n",
    "\n",
    "    # Bin \"average\" (ignoring missing values) the data with bin widths tau.\n",
    "\n",
    "    pd_caln = t_subsample(pdr,tau,calInt)\n",
    "    pd_valn = t_subsample(pdr,tau,valInt)\n",
    "\n",
    "    # min number of averaged obs to have in a record calibration interval\n",
    "    fracnnan = 0.9\n",
    "    Nmin = round(fracnnan*len(pd_caln))\n",
    "\n",
    "    # Identify proxies that have more than Nmin obs in the cal interval and more than 2 obs in the val interval (needed to make a prediction)...\n",
    "    tokeep = ((~pd_caln.isnull()).sum()>Nmin) & ((~pd_valn.isnull()).sum()>2)\n",
    "\n",
    "    # ...and eliminate the rest. Linearly interpolate to estimate missing data in cal interval\n",
    "    pd_cal = pd_caln.loc[:,tokeep].interpolate()\n",
    "    pd_val = pd_valn.loc[:,tokeep].interpolate()\n",
    "    pm = pmr.loc[tokeep]\n",
    "\n",
    "    # Do this again: there could still be NaNs because of edge effects in interpolating\n",
    "    tokeep2 = ~(pd_cal.isnull().sum()>0) & ((~pd_val.isnull()).sum()>0)\n",
    "    pd_cal = pd_cal.loc[:,tokeep2]\n",
    "    pd_val = pd_val.loc[:,tokeep2]\n",
    "    pm = pm.loc[tokeep2]\n",
    "\n",
    "#########################################\n",
    "## Normalize ##\n",
    "#########################################\n",
    "\n",
    "    pd_cal = (pd_cal - pd_cal.mean())/pd_cal.std()\n",
    "    pd_val = (pd_val - pd_val.mean())/pd_val.std()\n",
    "\n",
    "\n",
    "#################################################\n",
    "## Compute a LIM over the calibration interval ##\n",
    "#################################################\n",
    "\n",
    "    ## See what happens when the LIM is computed\n",
    "    De = pd_cal.values\n",
    "    tau = 1\n",
    "    l,m = De.shape\n",
    "    Dt  = De.transpose()\n",
    "    c0 = np.cov(Dt)\n",
    "    ctfull = np.cov(Dt[:,tau:],Dt[:,:-tau])\n",
    "\n",
    "    #c0 = ctfull[:m,:m]\n",
    "    # relelvant portion is one of the off-diagonal covariance submatrices\n",
    "    ct = ctfull[m:,:-m]\n",
    "\n",
    "    G = np.dot(ct,linalg.pinv(c0,cond=.1))\n",
    "\n",
    "#    G = makeLIM(pd_cal.values,tau)\n",
    "\n",
    "##############################################################################\n",
    "## Simulate values in the validation interval at tau leads and compute RMSE ##\n",
    "##############################################################################\n",
    "# Maybe should not include interpolated times?\n",
    "\n",
    "    pred = np.dot(G,pd_val.values.transpose())\n",
    "    rmse = np.sqrt(np.mean((pd_val.values.transpose()[:,1:]-pred[:,:-1])**2,1))\n",
    "\n",
    "    rdf = pandas.DataFrame(columns=pd_val.columns)\n",
    "    rdf.loc[1] = rmse\n",
    "\n",
    "#################\n",
    "## Make plots! ##\n",
    "#################\n",
    "\n",
    "    plt.matshow((c0))\n",
    "    ttl = plt.title('Lag 0 covariance')\n",
    "    ttl.set_position([.5, 1.15])\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    plt.matshow(ct)\n",
    "    plt.colorbar()\n",
    "    ttl = plt.title('Lag ' + str(tau) + ' year covariance')\n",
    "    ttl.set_position([.5, 1.1])\n",
    "    plt.show()\n",
    "\n",
    "    plt.matshow(G)\n",
    "    plt.colorbar()\n",
    "    ttl = plt.title('G matrix')\n",
    "    ttl.set_position([.5, 1.1])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    lat4 = pm['Lat_N'].values\n",
    "    lon4 = pm['Lon_E'].values\n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    m = Basemap(projection='moll',llcrnrlat=-87,urcrnrlat=81,lon_0=0,\\\n",
    "                llcrnrlon=0,urcrnrlon=360,resolution='c');\n",
    "    # draw parallels and meridians.\n",
    "    parallels = np.arange(-90.,90.,30.)\n",
    "    # Label the meridians and parallels\n",
    "    m.drawparallels(parallels,labels=[False,True,True,False])\n",
    "    # Draw Meridians and Labels\n",
    "    meridians = np.arange(-180.,181.,30.)\n",
    "    m.drawmeridians(meridians)\n",
    "    m.drawmapboundary(fill_color='white')\n",
    "\n",
    "    x,y = m(lon4,lat4)\n",
    "    sc = plt.scatter(x,y, c=rdf,edgecolors='none', cmap='seismic', s=20)\n",
    "    cbar = plt.colorbar(sc, shrink = .7)\n",
    "    cbar.set_label('Normalized units')\n",
    "    m.drawcoastlines()\n",
    "    plt.title('Prediction RMSE',size=20)\n",
    "    plt.show();\n",
    "\n",
    "############################\n",
    "## Compute and output RMSE ##\n",
    "#############################\n",
    "\n",
    "    return rdf,G,c0,ct,pm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run lots of experiments!\n",
    "\n",
    "tau = 10\n",
    "calInt = [1500,1850]\n",
    "valInt = calInt\n",
    "#valInt = [1850,1900]\n",
    "\n",
    "# Groups can be any of the following, coded by letters as specified in this dict:\n",
    "# data_dict = {'c': 'Corals_and_Sclerosponges', \n",
    "#             'i': 'Ice_Cores', \n",
    "#             'l': 'Lake_Cores',\n",
    "#             'm': 'Marine_Cores',\n",
    "#             's': 'Speleothems',\n",
    "#             't': 'Tree_Rings'}\n",
    "data_types = {'c', 'i','l','m','s','t'}\n",
    "\n",
    "rdf,G,c0,ct,pmSkill = getSkill(data_types,proxy_data,proxy_meta,tau,calInt,valInt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t_subsample(recdf,tau,interval):\n",
    "    '''Takes an array record and bin averages it (using nanmean) into bins of length tau. If the length of rec is not an integer multiple of tau, then the interval will be truncated.\n",
    "\n",
    "recdf: DataFrame of the form of proxy_data (columns are records, indexed by year)\n",
    "tau: bin width\n",
    "interval: two-element array giving the start and end years. Make sure that these are a subset of the indices of recdf; there is nothing to catch an error if this is not true and I'm not sure what will happen.\n",
    "'''\n",
    "\n",
    "    # Compute new times.\n",
    "    intl = int(np.diff(interval))\n",
    "    newt = np.arange(interval[0],interval[1],tau) + tau/2\n",
    "\n",
    "    # define a new dataframe to populate\n",
    "    df = pandas.DataFrame(index=newt)\n",
    "\n",
    "    # Loop through different records, bin them, and populate df with binned values\n",
    "\n",
    "    for ii in np.arange(0,len((recdf.columns))-1):\n",
    "        rec = recdf.iloc[interval[0]:(interval[1]-np.mod(intl,tau)),ii].values\n",
    "        rr = rec.reshape(tau,-1)\n",
    "        r = np.nanmean(rr,0)\n",
    "        df[recdf.columns[ii]] = pandas.DataFrame(data=r,index=newt)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "    # pad end of record to be an integer multiple of tau\n",
    "    #rec = np.concatenate([rec,np.ones(tau-np.mod(len(rec),tau))*np.nan])\n",
    "    # reshape rec to facilitate averaging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a map of data locations\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "m = Basemap(projection='moll',llcrnrlat=-87,urcrnrlat=81,lon_0=0,\\\n",
    "            llcrnrlon=0,urcrnrlon=360,resolution='c');\n",
    "# draw parallels and meridians.\n",
    "parallels = np.arange(-90.,90.,30.)\n",
    "# Label the meridians and parallels\n",
    "m.drawparallels(parallels,labels=[False,True,True,False])\n",
    "# Draw Meridians and Labels\n",
    "meridians = np.arange(-180.,181.,30.)\n",
    "m.drawmeridians(meridians)\n",
    "m.drawmapboundary(fill_color='white')\n",
    "\n",
    "\n",
    "mkr_dict = {'Corals_and_Sclerosponges': '^', 'Ice_Cores': '+', 'Lake_Cores': 'o','Marine_Cores':'d','Speleothems':'s','Tree_Rings':'x'}\n",
    "\n",
    "groups = proxy_meta.groupby('Archive_type')\n",
    "for name, group in groups:\n",
    "    x,y = m(group.Lon_E.values,group.Lat_N.values)\n",
    "    oldest = group.Oldest_CE.values\n",
    "    sc = plt.scatter(x, y, c=oldest, marker = mkr_dict[name], s=100, label=name.replace('_',' '),edgecolors='none')\n",
    "\n",
    "plt.legend(loc='center', bbox_to_anchor=(.15, .15),fancybox=True)\n",
    "cbar = plt.colorbar(shrink = .7)\n",
    "plt.clim(1000,2000)\n",
    "cbar.set_label('Oldest age in record',size=16)\n",
    "m.drawcoastlines()\n",
    "plt.title('Proxies in the LMR network',size=20)\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "groups = proxy_meta.groupby('Archive_type')\n",
    "\n",
    "## Groups can be any of the following, coded by letters as specified in this dict:\n",
    "data_dict = {'c': 'Corals_and_Sclerosponges', \n",
    "             'i': 'Ice_Cores', \n",
    "             'l': 'Lake_Cores',\n",
    "             'm': 'Marine_Cores',\n",
    "             's': 'Speleothems',\n",
    "             't': 'Tree_Rings'}\n",
    "\n",
    "# **************************************\n",
    "\n",
    "## This is where data types are selected!\n",
    "## To select more than one proxy type, e.g. all but tree ring records:\n",
    "# data_types = {'c' 'i' 'l' 'm' 's'}\n",
    "\n",
    "# **************************************\n",
    "\n",
    "data_types = {'c', 'i', 'm', 'l', 't'}\n",
    "\n",
    "tr = pandas.DataFrame()\n",
    "for x in data_types:\n",
    "    test = groups.get_group(data_dict[x])\n",
    "    tr = pandas.concat([tr,test])\n",
    "\n",
    "# proxy_data with these records only\n",
    "pdr = proxy_data[tr.index]\n",
    "\n",
    "# interpolated proxy data. Time window is little wider at first to help with interpolating edges\n",
    "\n",
    "pd_nans = pdr.loc[1800:1900].interpolate()\n",
    "\n",
    "# min number of obs to have in a record\n",
    "Nmin = 50\n",
    "\n",
    "# Select records with more than Nmin observations over 1800:1900\n",
    "g30 = (~proxy_data.loc[1800:1900].isnull()).sum()>Nmin\n",
    "\n",
    "# Find all records without lingering NaNs...\n",
    "tokeep = ((~proxy_data.loc[1800:1900].isnull()).sum()>50) & ~pd_nans.isnull().any()\n",
    "\n",
    "# ...and eliminate the rest\n",
    "pd = pd_nans.loc[:,tokeep]\n",
    "pm = proxy_meta.loc[tokeep]\n",
    "\n",
    "# Normalize\n",
    "pn = (pd - pd.mean())/pd.std()\n",
    "\n",
    "# Plot map\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "m = Basemap(projection='moll',llcrnrlat=-87,urcrnrlat=81,lon_0=0,\\\n",
    "            llcrnrlon=0,urcrnrlon=360,resolution='c');\n",
    "# draw parallels and meridians.\n",
    "parallels = np.arange(-90.,90.,30.)\n",
    "# Label the meridians and parallels\n",
    "m.drawparallels(parallels,labels=[False,True,True,False])\n",
    "# Draw Meridians and Labels\n",
    "meridians = np.arange(-180.,181.,30.)\n",
    "m.drawmeridians(meridians)\n",
    "m.drawmapboundary(fill_color='white')\n",
    "\n",
    "# Loop through groups to plot with different markers\n",
    "groups = pm.groupby('Archive_type')\n",
    "for name, group in groups:\n",
    "    x,y = m(group.Lon_E.values,group.Lat_N.values)\n",
    "    oldest = group.Oldest_CE.values\n",
    "    sc = plt.scatter(x, y, marker = mkr_dict[name], s=100, label=name.replace('_',' '),edgecolors='none')\n",
    "\n",
    "plt.legend(loc='center', bbox_to_anchor=(.15, .15),fancybox=True)\n",
    "m.drawcoastlines()\n",
    "plt.title('Proxies in the LMR network with more than ' + str(Nmin) + ' obs between 1800 and 1900',size=20)\n",
    "plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the records selected in the previous cell in a large stack\n",
    "plt.figure(figsize=(7,20))\n",
    "lpn,mpn=pn.shape\n",
    "# spacing between time series\n",
    "spc = 2;\n",
    "pns = pn+np.outer(np.ones(lpn)*spc,np.arange(1,mpn+1));\n",
    "plt.plot(pns.iloc[:,:100],color='k');\n",
    "plt.autoscale(enable=True, axis='both', tight=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EOFs of just the normalized data over 1800-1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##### EOFs of just the normalized data over 1800-1900 (no spatial averaging)\n",
    "\n",
    "#  Compute SVD\n",
    "U, s, V = np.linalg.svd(pn.values, full_matrices=False)\n",
    "\n",
    "# Plot the fraction of variance accounted for by EOFs\n",
    "plt.plot(np.cumsum(np.square(s)/np.sum(np.square(s))),'.');\n",
    "plt.title('Cumulative fraction of variance accounted for by EOFs')\n",
    "plt.show()\n",
    "\n",
    "# Plot the first 4 leading PCs\n",
    "plt.plot(V[:,0:4])\n",
    "plt.legend('12345',loc=3,ncol=2)\n",
    "plt.title('First 4 leading PCs')\n",
    "plt.show()\n",
    "\n",
    "# Make the singular vectors into dataframes\n",
    "#Udf = pd.DataFrame(U,pn.index)\n",
    "#Vdf = pd.DataFrame(V,range(1,102),pn.columns)\n",
    "\n",
    "# Plot the leading left SV\n",
    "\n",
    "lat3 = pm['Lat_N'].values\n",
    "lon3 = pm['Lon_E'].values\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "m = Basemap(projection='moll',llcrnrlat=-87,urcrnrlat=81,lon_0=0,\\\n",
    "            llcrnrlon=0,urcrnrlon=360,resolution='c');\n",
    "# draw parallels and meridians.\n",
    "parallels = np.arange(-90.,90.,30.)\n",
    "# Label the meridians and parallels\n",
    "m.drawparallels(parallels,labels=[False,True,True,False])\n",
    "# Draw Meridians and Labels\n",
    "meridians = np.arange(-180.,181.,30.)\n",
    "m.drawmeridians(meridians)\n",
    "m.drawmapboundary(fill_color='white')\n",
    "\n",
    "x,y = m(lon3,lat3)\n",
    "sc = plt.scatter(x,y, c=V[0,:],edgecolors='none', cmap='seismic', s=20)\n",
    "cbar = plt.colorbar(sc, shrink = .7)\n",
    "cbar.set_label('Normalized units')\n",
    "m.drawcoastlines()\n",
    "plt.title('Leading EOF (annually resolved proxies 1800-1900)',size=20)\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make LIM from ungridded data\n",
    "TAU = 1\n",
    "\n",
    "## Regularize to avoid singular covariance matrices by switching to EOF space\n",
    "[u,s,v] = np.linalg.svd(np.transpose(pn.values),full_matrices=True)\n",
    "\n",
    "# Tolerance for SVD truncation\n",
    "tol = s.max()/100.\n",
    "ks = s>tol\n",
    "\n",
    "# in the EOF basis:\n",
    "De = np.transpose(np.dot(np.diag(s[ks]),(v[:sum(ks),:])))\n",
    "\n",
    "## See what happens when the LIM is computed\n",
    "tau = 1\n",
    "l,m = De.shape\n",
    "Dt  = De.transpose()\n",
    "c0 = np.cov(Dt)\n",
    "ctfull = np.cov(Dt[:,tau:],Dt[:,:-tau])\n",
    "\n",
    "#c0 = ctfull[:m,:m]\n",
    "# relelvant portion is one of the off-diagonal covariance submatrices\n",
    "ct = ctfull[m:,:-m]\n",
    "\n",
    "plt.matshow(c0)\n",
    "ttl = plt.title('Covariance in EOF space')\n",
    "ttl.set_position([.5, 1.15])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.matshow(ct)\n",
    "plt.colorbar()\n",
    "ttl = plt.title('Lag covariance in EOF space')\n",
    "ttl.set_position([.5, 1.1])\n",
    "plt.show()\n",
    "\n",
    "## Compute and plot LIM\n",
    "G = makeLIM(De,TAU)\n",
    "plt.matshow(G)\n",
    "plt.title('G')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "B = 1/TAU*linalg.logm(G)\n",
    "\n",
    "[eB,evB] = linalg.eig(B)\n",
    "[e,ev] = linalg.eig(G)\n",
    "\n",
    "plt.plot(np.real(np.log(e)))\n",
    "plt.title('Real part of log eigenvalues of G')\n",
    "plt.show()\n",
    "plt.plot(np.imag(np.log(e)))\n",
    "plt.title('Imaginary part of log eigenvalues of G')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(ev[:,:4]);\n",
    "plt.title('Eigenvectors of G')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### SVD of gridded data\n",
    "\n",
    "## Pre-process and compute SVD\n",
    "\n",
    "# Find data that aren't NaNs\n",
    "mask = ~np.isnan(G[1,:,:])\n",
    "\n",
    "# Select those time series\n",
    "g = G[:,mask];\n",
    "\n",
    "# SVD. Transpose so that U are EOFs\n",
    "U, s, V = np.linalg.svd(g.transpose(), full_matrices=False)\n",
    "\n",
    "## Plot singular values\n",
    "\n",
    "# Put EOFs back on a spatial grid\n",
    "l,m,n = G.shape\n",
    "Umap = np.empty([m,n])*np.nan\n",
    "Umap[mask] = U[:,1]\n",
    "\n",
    "\n",
    "# Plot the fraction of variance accounted for by EOFs\n",
    "plt.plot(np.cumsum(np.square(s)/np.sum(np.square(s))),'.');\n",
    "plt.title('Cumulative fraction of variance accounted for by EOFs')\n",
    "plt.xlabel('SVD index')\n",
    "plt.ylabel('Normalized proxy units squared')\n",
    "plt.show()\n",
    "\n",
    "# Plot the first 4 leading PCs\n",
    "plt.plot(V[:,0:4])\n",
    "plt.legend('12345',loc=3,ncol=2)\n",
    "plt.title('First 4 leading PCs')\n",
    "plt.xlabel('SVD index')\n",
    "plt.ylabel('Normalized')\n",
    "plt.show()\n",
    "\n",
    "# Mask and plot with basemap\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "m = Basemap(projection='moll',llcrnrlat=-87,urcrnrlat=81,lon_0=0,\\\n",
    "            llcrnrlon=0,urcrnrlon=360,resolution='c');\n",
    "# draw parallels and meridians.\n",
    "parallels = np.arange(-90.,90.,30.)\n",
    "# Label the meridians and parallels\n",
    "m.drawparallels(parallels,labels=[False,True,True,False])\n",
    "# Draw Meridians and Labels\n",
    "meridians = np.arange(-180.,181.,30.)\n",
    "m.drawmeridians(meridians)\n",
    "m.drawmapboundary(fill_color='white')\n",
    "\n",
    "x,y = np.meshgrid(lon_g[:-1], lat_g[:-1])\n",
    "\n",
    "ax = plt.gca()\n",
    "masked_array = np.ma.array(Umap, mask=(np.isnan(Umap)))\n",
    "cmap = matplotlib.cm.seismic\n",
    "cmap.set_bad('white',1.0)\n",
    "\n",
    "im1 = m.pcolormesh(x,y,Umap,shading='flat',cmap=cmap,latlon=True);\n",
    "im2 = m.pcolormesh(x,y,masked_array,shading='flat',cmap=cmap,latlon=True);\n",
    "m.drawcoastlines();\n",
    "cbar = plt.colorbar(im1,shrink=.7)\n",
    "plt.title('Leading EOF for ' + str(RES) + '-degree gridded data',size=20)\n",
    "cbar.set_label('Normalized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Compute a spatially averaged field\n",
    "\n",
    "RES = 4;\n",
    "Gn, pmg, lat_g,lon_g = gridAvg(pm,pn,RES)\n",
    "# Define a grid. RES is resolution in degrees.\n",
    "# Mask and plot with basemap\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "m = Basemap(projection='moll',llcrnrlat=-87,urcrnrlat=81,lon_0=0,\\\n",
    "            llcrnrlon=0,urcrnrlon=360,resolution='c');\n",
    "# draw parallels and meridians.\n",
    "parallels = np.arange(-90.,90.,30.)\n",
    "# Label the meridians and parallels\n",
    "m.drawparallels(parallels,labels=[False,True,True,False])\n",
    "# Draw Meridians and Labels\n",
    "meridians = np.arange(-180.,181.,30.)\n",
    "m.drawmeridians(meridians)\n",
    "m.drawmapboundary(fill_color='white')\n",
    "\n",
    "x,y = np.meshgrid(lon_g[:-1], lat_g[:-1])\n",
    "\n",
    "ax = plt.gca()\n",
    "masked_array = np.ma.array(Gn, mask=(Gn==0))\n",
    "cmap = matplotlib.cm.jet\n",
    "cmap.set_bad('white',1.0)\n",
    "\n",
    "im1 = m.pcolormesh(x,y,Gn,shading='flat',cmap=cmap,latlon=True);\n",
    "im2 = m.pcolormesh(x,y,masked_array,shading='flat',cmap=cmap,latlon=True);\n",
    "m.drawcoastlines();\n",
    "cbar = plt.colorbar(im1,shrink=.7)\n",
    "plt.title(str(RES) + '-degree gridded data',size=20)\n",
    "cbar.set_label('Number of records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make LIM from gridded data\n",
    "TAU = 1\n",
    "\n",
    "# Find data that aren't NaNs\n",
    "mask = ~np.isnan(G[1,:,:])\n",
    "\n",
    "# Select those time series\n",
    "g = G[:,mask];\n",
    "\n",
    "## Regularize to avoid singular covariance matrices by switching to EOF space\n",
    "[u,s,v] = np.linalg.svd(np.transpose(g),full_matrices=True)\n",
    "\n",
    "# Tolerance for SVD truncation\n",
    "tol = s.max()/100.\n",
    "ks = s>tol\n",
    "\n",
    "# in the EOF basis:\n",
    "De = np.transpose(np.dot(np.diag(s[ks]),(v[:sum(ks),:])))\n",
    "\n",
    "## See what happens when the LIM is computed\n",
    "tau = 1\n",
    "l,m = De.shape\n",
    "Dt  = De.transpose()\n",
    "c0 = np.cov(Dt)\n",
    "ctfull = np.cov(Dt[:,tau:],Dt[:,:-tau])\n",
    "\n",
    "#c0 = ctfull[:m,:m]\n",
    "# relelvant portion is one of the off-diagonal covariance submatrices\n",
    "ct = ctfull[m:,:-m]\n",
    "\n",
    "plt.matshow(c0)\n",
    "ttl = plt.title('Covariance in EOF space')\n",
    "ttl.set_position([.5, 1.15])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.matshow(ct)\n",
    "plt.colorbar()\n",
    "ttl = plt.title('Lag covariance in EOF space')\n",
    "ttl.set_position([.5, 1.1])\n",
    "plt.show()\n",
    "\n",
    "## Compute and plot LIM\n",
    "G = makeLIM(De,TAU)\n",
    "plt.matshow(G)\n",
    "plt.title('G')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "B = 1/TAU*linalg.logm(G)\n",
    "\n",
    "[eB,evB] = linalg.eig(B)\n",
    "[e,ev] = linalg.eig(G)\n",
    "\n",
    "plt.plot(np.real(np.log(e)))\n",
    "plt.title('Real part of log eigenvalues of G')\n",
    "plt.show()\n",
    "plt.plot(np.imag(np.log(e)))\n",
    "plt.title('Imaginary part of log eigenvalues of G')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(ev[:,:4]);\n",
    "plt.title('Eigenvectors of G')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
